\documentclass[11pt,fleqn]{article}
\usepackage[margin=1in,top=1in,bottom=1in]{geometry}
\usepackage{tikz}
\usepackage{mathtools}
\usepackage{longtable}
\usepackage{enumitem}
\usepackage[hidelinks]{hyperref}
%\usepackage[dvips]{graphics}
%\usepackage[table]{xcolor}
%\usepackage{amssymb}
\usepackage{float}
%\usepackage{subfig}
\usepackage{booktabs}
\usepackage{subcaption}
\usepackage{colortbl}

\usepackage[normalem]{ulem}

\usepackage{multicol}
\usepackage{txfonts}
\usepackage{amsfonts}
\usepackage{natbib}
\usepackage{gb4e}
\usepackage[all]{xy}
\usepackage{rotating}
\usepackage{tipa}
\usepackage{multirow}
\usepackage{authblk}
\usepackage{url}
\usepackage{pdflscape}
\usepackage{rotating}
\usepackage{adjustbox}
\usepackage{array}


\def\bad{{\leavevmode\llap{*}}}
\def\marginal{{\leavevmode\llap{?}}}
\def\verymarginal{{\leavevmode\llap{??}}}
\def\swmarginal{{\leavevmode\llap{4}}}
\def\infelic{{\leavevmode\llap{\#}}}

\definecolor{airforceblue}{rgb}{0.36, 0.54, 0.66}
%\definecolor{gray}{rgb}{0.36, 0.54, 0.66}

\definecolor{Pink}{RGB}{240,0,120}
\newcommand{\red}[1]{\textcolor{Pink}{#1}}
\newcommand{\jd}[1]{\textbf{\textcolor{Pink}{[jd: #1]}}}
\definecolor{green}{RGB}{0,158,115}
\definecolor{orange}{RGB}{213,94,0}

\newcommand{\dashrule}[1][black]{%
  \color{#1}\rule[\dimexpr.5ex-.2pt]{4pt}{.4pt}\xleaders\hbox{\rule{4pt}{0pt}\rule[\dimexpr.5ex-.2pt]{4pt}{.4pt}}\hfill\kern0pt%
}

\setlength{\parindent}{.3in}
\setlength{\parskip}{0ex}

\newcommand{\yi}{\'{\symbol{16}}}
\newcommand{\nasi}{\~{\symbol{16}}}
\newcommand{\hina}{h\nasi na}
\newcommand{\ina}{\nasi na}

\newcommand{\foc}{$_{\mbox{\small F}}$}

\hyphenation{par-ti-ci-pa-tion}

\setlength{\bibhang}{0.5in}
\setlength{\bibsep}{0mm}
\bibpunct[:]{(}{)}{,}{a}{}{,}

\newcommand{\6}{\mbox{$[\hspace*{-.6mm}[$}} 
\newcommand{\9}{\mbox{$]\hspace*{-.6mm}]$}}
\newcommand{\sem}[2]{\6#1\9$^{#2}$}
\renewcommand{\ni}{\~{\i}}

\newcommand{\citepos}[1]{\citeauthor{#1}'s \citeyear{#1}}
\newcommand{\citeposs}[1]{\citeauthor{#1}'s}
\newcommand{\citetpos}[1]{\citeauthor{#1}'s (\citeyear{#1})}

\newcolumntype{R}[2]{%
    >{\adjustbox{angle=#1,lap=\width-(#2)}\bgroup}%
    l%
    <{\egroup}%
}
\newcommand*\rot{\multicolumn{1}{R{90}{0em}}}% no optional argument here, please!

\newcommand*\rots{\multicolumn{1}{R{90}{.7em}}}% no optional argument here, please!

% positive coefficients/difference
\definecolor{yellow1}{RGB}{102,102,0} 
\definecolor{yellow2}{RGB}{153,153,0} 
\definecolor{yellow3}{RGB}{204,204,0} 
\definecolor{yellow4}{RGB}{255,255,204}
%\definecolor{green1}{RGB}{0, 158, 115} % >.95
%\definecolor{green2}{RGB}{55, 185, 141} % .85-.95
%\definecolor{green3}{RGB}{88, 214, 167} % .75-.85
%\definecolor{green4}{RGB}{119, 242, 194} % <.75

% negative coefficients/difference
\definecolor{purple1}{RGB}{150,57,109}
\definecolor{purple2}{RGB}{188,78,139}
\definecolor{purple3}{RGB}{215,149,186}
\definecolor{purple4}{RGB}{236,206,223}

\title{I don't know if projection is categorical. \\ Did \citealt{mandelkern-etal2020} discover that it is?}

\author[$\circ$]{Judith Tonhauser}
\author[$\bullet$]{Judith Degen}
\affil[$\circ$]{University of Stuttgart}
\affil[$\bullet$]{Stanford University}

\renewcommand\Authands{ and }

\newcommand{\jt}[1]{\textbf{\color{blue}JT: #1}}

\begin{document}

\maketitle


\begin{abstract}

Presuppositions are taken to typically project out of entailment-canceling environments like the scope of negation (e.g., \citealt{ccmg90}). While projection is often characterized as categorical (that is, content either typically projects or not), there is mounting empirical evidence that projection is gradient, with content being more or less projective (e.g., \citealt{karttunen71b,xue-onea11,demarneffe-etal-sub23,tbd-variability,degen-tonhauser-language}). \citealt{mandelkern-etal2020} critically evaluated the inference rating measures on which this empirical evidence is based and claimed that naturalness ratings in explicit ignorance contexts are more suitable to measure categorical projection and, thereby, to distinguish presuppositions from nonpresuppositions. This paper presents the results of an experiment designed to investigate whether the measure proposed by \citealt{mandelkern-etal2020} can distinguish factive predicates (presumed presupposition triggers) from nonfactive ones (nontriggers). The results do not support \citepos{mandelkern-etal2020} claim as they do not provide evidence for a categorical distinction between presuppositions and nonpresuppositions. {\bf FIX: Furthermore, the results suggest that naturalness ratings in explicit ignorance contexts may be sensitive to a variety of semantic and pragmatic properties of utterances in addition to the felicity conditions of anaphoric projective content.}

\end{abstract}

\bigskip

\noindent
{\bf Keywords:} Presuppositions, categorical vs.\ gradient projection, inference ratings, naturalness ratings in explicit ignorance contexts. 

\bigskip

\noindent
{\bf Acknowledgments:} 

\noindent
For helpful comments on this project we thank Craige Roberts, Gregory Scontras, Mandy Simons, and the audience at the syntax/semantics discussion group at the University of Stuttgart.

\newpage
		
\section{Introduction}\label{s1}

Presuppositions are often characterized as content that typically projects out of entailment-canceling environments, like the scope of negation or a polar interrogative (e.g., \citealt{ccmg90}).\footnote{Conventional implicatures also project out of these environments. They differ from presuppositions in that they contribute novel information. For discussion see, e.g., \citealt{ccmg90,potts05}.} Thus, a content like the content of the clausal complement (CC) of {\em know} in (\ref{first}a) is taken to be a presupposition because a speaker who utters (\ref{first}a) is typically taken to believe the CC, that Julian dances salsa, even though the clausal complement occurs in a polar interrogative. By contrast, the CC of {\em think} in (\ref{first}b) is not assumed to be a presupposition because it does not typically project. Accordingly, {\em know} is analyzed as a presupposition trigger, but {\em think} is not.

\begin{exe}
\ex\label{first} 
\begin{xlist}
\ex Does Cole know that Julian dances salsa?
\ex Does Cole think that Julian dances salsa?
\end{xlist}
\end{exe}

Many theoretical works assume that projection is a categorical property of utterance content, that is, content either typically projects (in which case it is a presupposition) or it does not (in which case it is not a presupposition). There is, however, mounting empirical evidence that projection is not a categorical property of  content but rather a gradient one, with content being more or less projective. The measure used to establish this evidence are inference rating measures: Such measures involve presenting participants with an utterance (like that in (\ref{first}a)) and contents (like the content that Julian dances salsa), and asking for ratings that are taken to reveal the existence or strength of the inference to the content. \citealt{karttunen71b}, for instance, suggested that the CCs of {\em regret} and {\em discover}, which he took to be presuppositions, exhibit projection variability in examples like (\ref{kart}). Specifically, he suggested that a speaker who utters (\ref{kart}a) believes that the addressee has not told the truth, whereas a speaker who utters (\ref{kart}b) ``is not sure about the truth of the complement'' (p.63).

\begin{exe}
\ex\label{kart}
\begin{xlist}
\ex Did you regret that you had not told the truth?
\ex Did you discover that you had not told the truth? \hfill (\citealt[63]{karttunen71b})
\end{xlist}
\end{exe}
More recently, experimental investigations have also observed projection variability between presuppositions (e.g., \citealt*{xue-onea11,demarneffe-etal-sub23,tbd-variability,degen-tonhauser-language}). \citealt{tbd-variability}, for instance, observed in their Exps.~1 that the CCs of {\em know, discover,} and {\em reveal} exhibit projection variability: The CC of {\em know} is more projective than that of {\em discover}, and the CC of {\em discover} is more projective than that of {\em reveal}. These results led \citealt[498]{tbd-variability} to propose that ``projectivity [\ldots is] a gradient property of content, rather than a categorical, categorical one''. Further support for this proposal comes from  investigations of both factive and nonfactive predicates in \citealt{degen-tonhauser-language}. In a series of experiments and analyses of existing datasets, this work not only found projection variability between the CCs of factive predicates, but also no empirical support for a categorical distinction in the projection of the CCs of factive and nonfactive predicates. This is because the CCs of both factive and nonfactive predicates were projective to varying degrees compared to nonprojective main clause content. A sample illustration of these results is given in Fig.~\ref{fig:dt1a} from their Exp.~1a, which shows the mean projection ratings of 5 factive predicates (in \color{orange}orange\color{black}) and 15 nonfactive predicates (in \color{green}green\color{black}).

\begin{figure}[h!]
\centering
\includegraphics[width=.8\textwidth]{../../results/main/13explicitIgnorance/graphs/mean-certainty-by-predicateType}
\caption{Mean certainty rating (measuring projection) of main clause (`MC') content and the CCs of the 20 \color{orange}factive \color{black} and \color{green}nonfactive \color{black} predicates investigated in Exp.~1a of \citealt{degen-tonhauser-language} (adapted by collapsing the nonfactive predicates into a single category). Error bars indicate 95\% bootstrapped confidence intervals. Violin plots indicate the kernel probability density of the individual participants' ratings.}\label{fig:dt1a}
\end{figure}

Recently,  \citealt*[\S6.2]{mandelkern-etal2020} challenged the hypothesis that projection is gradient by arguing that inference rating measures are not suitable to detect categorical projection. Such measures are not suitable, they argued, because they do not distinguish between, on the one hand, contents that project because they are presuppositions and, on the other hand, contents that project because they are ``a natural conclusion to draw for any of a variety of pragmatic reasons short of entailment or presupposition'' (p.497). Inference rating measures, they suggested, might invite participants to draw projection inferences even when not lexically required because ``the content in question is right there before the [participants'] eyes" (p.498). They concluded that ``we should think twice before embracing a notion of presupposition projection that is gradient based on results from inference tasks alone'' (p.497).

\citealt[\S6.2]{mandelkern-etal2020} suggested that naturalness ratings of utterances in explicit ignorance contexts are better suited to distinguish presuppositions from nonpresuppositional projection inferences.\footnote{\citealt{mandelkern-etal2020} refer to the measure as an acceptability rating measure, but since participants were asked to rate the naturalness of utterances, we refer to it as a naturalness rating measure.} On this measure, participants are presented with utterances in which a speaker states that they are ignorant about a content, as in (\ref{mtrig}a), and then follows up with an utterance in which the content occurs embedded in an entailment-canceling environment, such as the antecedent of a conditional in (\ref{mtrig}c). \citealt{mandelkern-etal2020} assumed that if the content is a presupposition (such as the pre-state content of {\em stop} in (\ref{mtrig}c)), the utterance is rated as unnatural in the explicit ignorance context because presuppositions are contents that the speaker believes to be true. That is, in such constellations,  participants ``will not have an alternative to interpreting the presupposition at the utterance level, and in turn seeing the utterance as infelicitous and the speaker as incoherent'' (p.497).  If, on the other hand, the content is not a presupposition (such as the pre-state content of {\em now frown on} in (\ref{mtrig}c)), the utterance is assumed to be natural: Even if participants might, in a different context, draw a projection inference ``for any of a variety of pragmatic reasons short of entailment or presupposition, [\ldots] they will tend to relinquish that inclination when there is pragmatic pressure to do so'' as in the explicit ignorance contexts (p.497). Both presuppositions and nonpresuppositions were expected to be judged as natural in the support contexts, which entail the relevant content, illustrated in (\ref{mtrig}b).

\begin{exe}
\ex\label{mtrig} \citealt[490f.]{mandelkern-etal2020}
\begin{xlist}
\ex Explicit ignorance context: \\ Mary always was involved in a lot of sports, but I don't know whether she ever did any yoga.
\ex Support context: \\ Mary always was involved in a lot of sports, and she used to do yoga, too.
\ex Sentence with presupposition / nonpresupposition: \\ If Mary \{has stopped / now frowns on\} doing yoga, then Matthew will interview her for his story.
\end{xlist}
\end{exe}
\citepos{mandelkern-etal2020} Exp.~3, which used the proposed measure, only provided limited empirical evidence for the hypothesis that projection is a categorical property of content. This is primarily because the goal of this work (including Exp.~3) was not to investigate this hypothesis, but rather whether presupposition projection in conjunctions is symmetric. The evidence provided in this work is also limited, however, because only four presupposition triggers and four nontriggers were investigated: The presupposition triggers were the change-of-state verbs {\em stop} and {\em continue}, and the two clause-embedding predicates {\em be aware} and {\em be happy}; the nontriggers were {\em now frown on, enjoy, hope} and {\em be sure}.
%\footnote{While their Exps.~1 and 2 investigated {\em frown on}, Exp.~3 investigated {\em now frown on}, as shown in (i). It is possible that the pre-state content contributed by this expression is projective: (i), for instance, appears to give rise to the projective content that Mary did not frown on doing yoga in the past. 
%
%\begin{exe}
%\exi{(i)} If Mary now frowns on doing yoga, then Matthew will interview her for his story. \hfill (\citealt[491]{mandelkern-etal2020})
%\end{exe}
%} 
In the control items of Exp.~3, these eight expressions were realized in (single-clause) antecedents of conditionals, as shown in (\ref{mtrig}c). Naturalness ratings were elicited in explicit ignorance and support contexts. 

\citealt{mandelkern-etal2020} found (as shown in their Fig.~3) that the naturalness ratings for the nontriggers in the control items were relatively high in both contexts (with means just below 5, where 1 meant ``completely unnatural'' and 7 meant ``completely natural'' on their 7-point Likert scale). The presupposition triggers, on the other hand, had a lower mean naturalness rating in the explicit ignorance context (mean around 3) than in the support context (mean just above 5). Mandelkern and his colleagues took this to ``establish[] the effectiveness of the methodology'' (p.492). They proposed (p.497):

\begin{quote}

[\ldots] comparing contexts which support the inference to contexts in which it has been made clear that the speaker is ignorant about the inference provides a way to distinguish a broad class of natural and invited pragmatic inferences from those that are really encoded as presuppositions, and thus have no choice but to project. [...]  In methodological terms, we strongly recommend at least a two-pronged approach, with careful attention paid to results stemming from the evaluation of acceptabilty [sic] in different contexts.

\end{quote}

However, an inspection of the naturalness ratings for the eight (non)triggers provided in Fig.~8 in their Appendix 3 raises doubt about whether the measure indeed provides evidence for a categorical distinction between presuppositions and nonpresuppositions. First, considering the mean naturalness ratings in the explicit ignorance contexts, we find ratings for the presuppositions range from just above 1 (for the pre-state of {\em continue}) to about 3.5 (for the CC of {\em be aware}). As the ratings for the nonpresuppositions range from just below 3 (for the CC of {\em hope}) to 4.5 (for the CC of {\em be aware}), it is not clear that naturalness ratings in explicit ignorance contexts provide evidence for a categorical distinction between the four presuppositions and the four nonpresuppositions investigated in \citealt{mandelkern-etal2020}. Second, the effect of context (explicit ignorance vs.\ support) also does not appear to be consistent for presuppositions or nonpresuppositions. Whereas the difference between the mean naturalness ratings in the explicit ignorance and support contexts was quite large for the (presuppositional) pre-state of {\em continue}, the difference was much less pronounced for the (presuppositional) CC of {\em be aware}, where it was roughly comparable to that of the (nonpresuppositional) pre-state of {\em frown on}. Thus, it is not clear that comparisons of ratings in support and explicit ignorance contexts provides empirical support for a categorical projection either. 

Adding to this, there is disagreement in the literature about the naturalness of presuppositions in explicit ignorance contexts. Whereas Mandelkern and his colleagues assumed that presuppositions are unnatural in explicit ignorance contexts, \citealt{simons01} and \citealt{abusch10} assumed that only `hard' (nondefeasible) presuppositions are, but that `soft' (defeasible) ones are natural. For instance,  the examples with {\em stop}, {\em discover}, and {\em win} in (\ref{eic2}) were assumed to be natural in explicit ignorance contexts, and the examples with {\em again}, the {\em it-}cleft and {\em too} in (\ref{eic3}) unnatural.\footnote{\citealt{abusch10} marked (\ref{eic3}b) and (\ref{eic3}c) with `??' instead of `$\#$'.} This disagreement about the naturalness of presuppositions in explicit ignorance contexts necessitates further investigation.

\begin{exe}
\ex\label{eic2}
\begin{xlist}
\ex I have no idea whether Jane ever smoked, but she hasn't stopped smoking. \hfill (\citealt[443]{simons01})
\ex Context: ``two people [\ldots] know that Henry is searching for Jane, but who don't themselves know where Jane is:'' \\ If Henry discovers that Jane is in New York, there'll be trouble. \hfill (\citealt[434]{simons01})
\ex I have no idea whether John ended up participating in the
Road Race yesterday. But if he won it, then he has more victories than anyone else in history. \hfill (\citealt[39]{abusch10})
\end{xlist}
\ex\label{eic3}
\begin{xlist}
\ex\infelic I don't know if Jane ever rented ``Manhattan'' before, but perhaps she's renting it again. \hfill (\citealt[443]{simons01})

\ex \infelic I have no idea whether anyone read that letter. But if it is John
who read it, let's ask him to be discreet about the content. \hfill (\citealt[40]{abusch10})

\ex \infelic I have no idea whether John read that proposal. But if Bill read it too, let's ask them to confer and simply give us a yes-no response. \hfill (\citealt[40]{abusch10})
\end{xlist}
\end{exe}

This paper presents the results of an experiment designed to investigate whether the measure proposed by \citealt{mandelkern-etal2020} provides evidence that projection is a categorical property of content rather than a gradient one.\footnote{Link to experiment, materials, and analysis scripts: \url{xxx}}  To allow for comparison with the results of \citealt{degen-tonhauser-language}, the CCs of the same 20 (non)factive clause-embedding predicates (see Fig.~\ref{fig:dt1a}) were investigated. The experiment also included control stimuli with {\em stop, continue, again, too, also}, and an {\em it-}cleft to allow for comparison with the results of \citealt{mandelkern-etal2020} and the assumptions made in \citealt{simons01} and \citealt{abusch10}. 

One change made to the design of \citepos{mandelkern-etal2020} Exp.~3 was that the experiment implemented a three-level context condition instead of a two-level one.\footnote{Another change was that participants gave their naturalness ratings on a slider with endpoints labeled `totally unnatural' and `totally natural' rather than on a 7-point Likert scale with endpoints labeled `completely unnatural' and `completely natural'.}  Specifically, \citepos{mandelkern-etal2020} support context (which entailed the relevant context, see (\ref{mtrig}b)) was replaced with two contexts that were compatible with the relevant content but did not entail it. The two contexts differed in the prior probability of the  content: In the `lower prior probability' context, illustrated in (\ref{prior}a), the  relevant content (in (\ref{prior}c), that Julian dances salsa) had a comparatively lower prior probability, whereas it had a comparatively higher prior probability in the `higher prior probability' context, illustrated in (\ref{prior}b). The two contexts for each of the 20 complement clauses that were combined with the 20 predicates were normed in \citealt{degen-tonhauser-openmind}. 

\begin{exe}
\ex\label{prior}
\begin{xlist}
\ex Julian is German. \hfill [lower prior probability]
\ex Julian is Cuban. \hfill [higher prior probability]
\ex Did Cole discover that Julian dances salsa?
\end{xlist}
\end{exe}
This change in the context condition was implemented to allow for comparison to the result of \citealt{degen-tonhauser-openmind} that the projection of content is sensitive to the content's prior probability. Specifically, this work found that the higher the prior probability of a content, the stronger the projection inference. Under standard analyses of presuppositions, like \citealt{heim83} or \citealt{vds92}, presuppositions are by default globally accommodated in contexts that are compatible with the presupposition, like the lower and higher prior probability contexts. Accordingly, such analyses predict that presuppositions are rated as natural in both lower and higher probability contexts, just as in \citepos{mandelkern-etal2020} support contexts. 

\section{Experiment}\label{s2}

To investigate whether the measure proposed in \citealt{mandelkern-etal2020} provides support for a categorical distinction between presuppositions and nonpresuppositions, participants read two-sentence discourses consisting of a declarative (which provided the context) and an interrogative (which realized a (non)factive clause-embedding predicate), and rated the naturalness of the interrogative in the context of the declarative.

\subsection{Methods}\label{s-methods}

\subsubsection{Participants}

We recruited 425 participants on Prolific. Due to a server error, the data of only 398 participants was recorded (ages: 19-73, mean: 40.8; 187 women, 201 men, 8 non-categorical, 2 preferred to not disclose). The recruited participants were required to live in the USA, to speak English as their first language, to have completed at least 100 tasks, and to have an approval rating of at least 99\%. The median time spent on the task was 6:24 minutes. Participants were paid \$1.78, corresponding to an hourly pay of \$16.6.


\subsubsection{Materials}

Participants read two-sentence discourses consisting of a declarative followed by an interrogative, as shown in (\ref{sample}). In the target stimuli, the interrogatives combined the 20 (non)factive predicates of \citealt{degen-tonhauser-language} (see Fig.~\ref{fig:dt1a}) with the 20 complement clauses of \citealt{degen-tonhauser-language}, for a total of 400 interrogatives. The preceding declaratives implemented a three-level context condition: In the `explicit ignorance' context (\ref{sample}a), the declarative sentence conveyed the speaker's ignorance about the CC. In the `lower prior probability' context (\ref{sample}b), the CC had a comparatively lower prior probability, whereas it had a comparatively higher prior probability in the `higher prior probability' context (\ref{sample}c). See Supplement \ref{a:clauses} for the full set of 20 complement clauses and the two contexts for each complement clause.

\begin{exe}
\ex\label{sample}
\begin{xlist}
\ex Explicit ignorance context: \\ I have no idea if Julian dances salsa. Does Cole discover that Julian dances salsa?
\ex Lower prior probability context: \\ Julian is German. Did Cole discover that Julian dances salsa?
\ex Higher prior probability context: \\ Julian is Cuban. Did Cole discover that Julian dances salsa?'
\end{xlist}
\end{exe}

In addition to the 1,200 target stimuli (400 interrogatives $\times$ 3 contexts), the materials also included the six control stimuli shown in (\ref{filler}). The interrogatives of the control stimuli featured six expressions typically analyzed as presupposition triggers, namely {\em stop, continue, again, too, also}, and an {\em it-}cleft. The preceding declaratives conveyed the speaker's explicit ignorance about the presuppositions associated with these expressions.\footnote{The contents investigated for {\em too} and {\em also} in (\ref{filler}d) and (\ref{filler}e) are that Ann plays an instrument other than the flute and that Svenja plays a sport other than soccer. This interpretation arises if {\em Ann} and {\em Svenja} associate with {\em too} and {\em also}, respectively. While prosody was not controlled for, this focus association is made plausible by the preceding explicit ignorance statements.} Two of these expressions, namely {\em stop} and {\em continue}, were target expressions in \citepos{mandelkern-etal2020} Exp.~3, where they were assumed to be unnatural in explicit ignorance contexts. This is in contrast to \citealt{simons01}, who took {\em stop} to be a soft trigger that is natural in explicit ignorance contexts. Three expressions were assumed to be unnatural in explicit ignorance contexts in \citealt{simons01} ({\em again}) and \citealt{abusch10} ({\em too}, {\em it-}cleft). The control stimuli were included for comparison to the target stimuli, to the claims of \citealt{simons01} and \citealt{abusch10}, and to the results of \citealt{mandelkern-etal2020}.

\begin{exe}
\ex\label{filler} 
\begin{xlist}
\ex I don't know if Stephen was ever in the habit of vaping. Has Stephen recently stopped vaping?
\ex I don't know if John was ever reading ``Dune''. Has John recently continued reading ``Dune''?
\ex I don't know if William was ever interested in history. Is William interested in history again?"
\ex I don't know if Ann plays any instrument. Does Ann play the flute, too?
\ex I don't know if Svenja plays any sport. Does Svenja also play soccer?
\ex I don't know if anyone was playing outside with the kids. Was it Jack who was playing outside with the kids?

\end{xlist}
\end{exe}

The experiment also included 4 filler stimuli that were used to exclude participants not attending to the task (see Supplement \ref{a:fillerPractice}). The filler stimuli were expected to receive high naturalness ratings.

A random set of 30 stimuli was created for each participant. Each set contained 20 target stimuli in which each of the 20 complement clauses was paired with a unique clause-embedding predicate. Twelve of the target stimuli were presented in the explicit ignorance context, and the other eight in a low or a higher prior probability context (four each). Each participants' set of 30 stimuli contained the same six control stimuli and the same four filler stimuli. Each of the 30 stimuli were presented as utterances by a unique named speaker. Trial order was randomized for each participant. 

\subsubsection{Procedure}

Participants were instructed to rate ``how natural the question sounds in the context of the statement''. As shown in Figure \ref{f:trials}, they were asked give their rating on a slider from `totally unnatural' (coded as 0) to `totally natural' (coded as 1). The experiment began with four practice trials to familiarize participants with the task (see Supplement \ref{a:fillerPractice} for details). After rating the 30 trials, participants filled out a short optional demographic survey. To encourage truthful responses, participants were told that they would be paid no matter what answers they gave in the survey.


\begin{figure}[h]
\centering
%\begin{subfigure}{0.49\textwidth}
\fbox{\includegraphics[width=.7\textwidth]{figures/trial-eic}}
%\caption{Trial with explicit ignorance context}
%\end{subfigure}
%\\[.1cm]
%\begin{subfigure}{0.49\textwidth}
%\fbox{\includegraphics[width=\textwidth]{figures/trial-low}}
%\caption{Trial with lower prior probability context}
%\end{subfigure} \hfill \begin{subfigure}{0.49\textwidth}
%\fbox{\includegraphics[width=\textwidth]{figures/trial-high}}
%\caption{Trial with higher prior probability context}
%\end{subfigure}
\caption{Sample trial with explicit ignorance context.}\label{f:trials}
\end{figure}


\subsubsection{Data exclusion} 

We excluded the data of five participants who did not self-identify as native speakers of American English as well as the data of 23 participants whose mean response to the  filler stimuli was more than 2 sd below the group mean.\footnote{Contrary to what was preregistered, one of the four filler stimuli was not used to exclude participants because it received a mean rating of only .5. See Supplement \ref{a:fillerPractice} for details.} The data of 370 participants entered into the analysis (ages: 19-80, mean: 40.7; 175 women, 185 male, 8 non-categorical, 2 preferred to not disclose). Each of the 20 predicates received at least 200 ratings in the explicit ignorance context (mean: 222 ratings), at least 59 ratings in the lower prior probability context (mean: 74), and at least 61 ratings in the higher prior probability context (mean: 74). The six control stimuli received 370 ratings each. 

\subsection{Results}

We first address the question of whether naturalness ratings in explicit ignorance contexts provide empirical evidence for a categorical difference between presuppositions and nonpresuppositions (\S\ref{s:analysis1}). We then consider whether a comparison of naturalness ratings in the three contexts provides such evidence (\S\ref{s:analysis2}).

\subsubsection{Naturalness ratings in explicit ignorance contexts}\label{s:analysis1}

Recall that \citealt{simons01} and \citealt{abusch10} assumed that only hard presuppositions are unnatural in explicit ignorance contexts, whereas \citealt{mandelkern-etal2020} assumed that all presuppositions are unnatural in such contexts. Figure \ref{fig:acc-by-expression} shows mean naturalness ratings in the explicit ignorance context by expression (in distinct colors: \color{orange}factive predicates\color{black}, \color{green}nonfactive predicates\color{black},  controls). As shown, the purported presupposition triggers, that is, the controls and the factive predicates, do not exhibit a unified pattern: The mean naturalness ratings of four controls ({\em continue, too, also, again}) are at floor, those of {\em stop} and {\em be annoyed} are a bit higher, those of the {\em it-}cleft and {\em know} are higher again, and those of {\em see, discover}, and {\em reveal} are just as high as those of some nonfactive predicates. These results do not provide empirical support for a categorical distinction between presuppositions and nonpresuppositions, contrary to what \citealt{mandelkern-etal2020} hypothesized. These results also do not provide support for a class of factive predicates that is categorically distinct from nonfactive predicates, in line with the result of \citealt{degen-tonhauser-language} based on inference rating measures. 

\begin{figure}[h!]
\centering
\includegraphics[width=.9\textwidth]{../../results/main/13explicitIgnorance/graphs/explicit-ignorance-naturalness-by-predicate}
\caption{Mean naturalness rating in explicit ignorance context by expression (\color{orange}factive\color{black}, \color{green}nonfactive\color{green}, \color{black}filler\color{black}). Error bars indicate 95\% bootstrapped confidence intervals. Overlaid violin plots indicate the kernel probability density of the participants' ratings.}\label{fig:acc-by-expression}
\end{figure}

These observations were confirmed by a posthoc pairwise comparison of the naturalness ratings of the contents associated with the six controls and 20 target expressions in the explicit ignorance context using the `emmeans' package (\citealt{emmeans}) in R (\citealt{r}). The input to the pairwise comparison was a Bayesian mixed-effects beta regression model with weakly informative priors that was fitted using the `brms' package (\citealt{buerkner2017}). The model predicted naturalness ratings from a fixed effect of expression (with treatment coding and `continue' as reference level) and included random by-participant and by-item intercepts (where an item is a complement clause). The pairwise comparison provided us with posterior distributions of estimated marginal means of pairwise differences between the contents associated with each of the 26 expression. We assume that two contents differ in their naturalness in the explicit ignorance context when the posterior distribution of their difference does not include 0. 

As shown in Table \ref{t:pairwise},\footnote{The full model output is available here: \url{LINK TO TABLE IN REPO}.} the pairwise comparison suggests differences between the naturalness ratings of the CCs of the five factive predicates, such that the ratings of {\em be annoyed} are lower than those of {\em know}, which in turn are lower than those of {\em see} and {\em discover}, which in turn are lower than those of {\em reveal}. There is also variation between the factive predicates and the presuppositional controls: The CCs of each of the five purportedly factive are more natural in explicit ignorance contexts than the presuppositions contributed by {\em too} and {\em also}. Furthermore, the naturalness ratings for the CCs of the five factive predicates are indistinguishable from different sets of expressions: The naturalness ratings for {\em be annoyed} do not differ from those of {\em stop} (but are higher than those the prejacents of the controls {\em continue, too}, and {\em also}), the naturalness ratings for {\em know} do not differ from those of the {\em it-}cleft, the naturalness ratings for {\em see} and {\em discover} do not differ from those of the nonfactives {\em confess, inform}, and {\em acknowledge}, and those of {\em reveal} do not differ from those of the nonfactives {\em admit, hear}, and {\em prove}. These results suggest that naturalness ratings in explicit ignorance contexts do not provide empirical support for a categorical distinction between factive and nonfactive predicates, or between presuppositions and nonpresuppositions.

%\begin{table}[!h]
%\addtolength{\tabcolsep}{-.1em}
%\centering
%\begin{tabular}{r ccccccccccccccccccccccccc}
%\toprule
% &  \rot{continue\color{black}} & \rot{too\color{black}} & \rot{also\color{black}} & \rot{again\color{black}} & \rot{stop\color{black}} & \rot{\color{orange}be annoyed\color{black}} & \rot{cleft\color{black}} & \rot{\color{orange}know\color{black}} & \rot{\color{green}demonstrate\color{black}} & \rot{\color{green}pretend\color{black}} & \rot{\color{green}inform\color{black}} & \rot{\color{green}confess\color{black}} & \rot{\color{orange}see\color{black}} & \rot{\color{green}acknowledge\color{black}} & \rot{\color{orange}discover\color{black}} & \rot{\color{green}admit\color{black}} & \rot{\color{green}hear\color{black}} & \rot{\color{green}prove\color{black}} & \rot{\color{orange}reveal\color{black}} & \rot{\color{green}announce\color{black}} & \rot{\color{green}be right\color{black}} & \rot{\color{green}establish\color{black}} & \rot{\color{green}confirm\color{black}} & \rot{\color{green}suggest\color{black}} & \rot{\color{green}think\color{black}} \\
% \midrule
%too & -- & \cellcolor{lightgray} & & & & & & & & & & & & & & & & \\
%also & -- & -- & \cellcolor{lightgray} & & & & & & & & & & & & & & & \\
%again  & -- & -- & -- & \cellcolor{lightgray} & & & & & & & & & & & & & & \\
%stop  & $\ast$ & $\ast$  & $\ast$ & $\ast$ & \cellcolor{lightgray} & & & & & & & & & & & & & \\
%\color{orange} be annoyed\color{black} & $\ast$ & $\ast$ & $\ast$ & -- & -- & \cellcolor{lightgray} & & & & & & & & & & & & \\
%cleft &  $\ast$ & $\ast$ & $\ast$& $\ast$ & $\ast$ & $\ast$ & \cellcolor{lightgray} & & & & & & & & & & & \\
%\color{orange} know\color{black}  & $\ast$ & $\ast$ & $\ast$&  $\ast$& $\ast$ & $\ast$ & -- & \cellcolor{lightgray} & & & & & & & & & & \\
%\color{green} demonstrate\color{black}  &  $\ast$   &$\ast$  & $\ast$ & $\ast$ &  $\ast$& $\ast$ & $\ast$ & $\ast$ & \cellcolor{lightgray} & & & & &  & & & & \\
%\color{green} pretend\color{black}  & $\ast$  &$\ast$  & $\ast$&  $\ast$&  $\ast$& $\ast$ & $\ast$ & $\ast$ & -- & \cellcolor{lightgray} & & & &  & & & & \\
%\color{green} inform\color{black}  & $\ast$  &$\ast$  & $\ast$&  $\ast$&  $\ast$& $\ast$ & $\ast$ & $\ast$ & -- & -- & \cellcolor{lightgray}& & &  & & & & \\
%\color{green} confess\color{black}  &  $\ast$ &$\ast$  & $\ast$&  $\ast$&  $\ast$& $\ast$ & $\ast$ & $\ast$ & $\ast$ & -- & -- & \cellcolor{lightgray} & &  & & & & \\
%\color{orange} see\color{black}  & $\ast$  & $\ast$ & $\ast$&  $\ast$&  $\ast$& $\ast$ & $\ast$ & $\ast$ & $\ast$ & -- &--  &-- & \cellcolor{lightgray} &  & & & & \\
%\color{green} acknowledge\color{black}  & $\ast$  & $\ast$ & $\ast$&  $\ast$&  $\ast$& $\ast$ & $\ast$ & $\ast$ & -- &--  &--  &--  &--  & \cellcolor{lightgray} & & & & \\
%\color{orange} discover\color{black}  &  $\ast$ & $\ast$ & $\ast$&  $\ast$&  $\ast$& $\ast$ &$\ast$  &$\ast$  &--  & -- &--  & -- &--  & -- & \cellcolor{lightgray} & & & \\
%\color{green} admit\color{black}  &  $\ast$ & $\ast$ & $\ast$&  $\ast$&  $\ast$& $\ast$ & $\ast$ &$\ast$  &$\ast$  & $\ast$ &$\ast$  &-- & -- & -- & -- & \cellcolor{lightgray} & & \\
%\color{green} hear\color{black}  & $\ast$  & $\ast$ & $\ast$&  $\ast$&  $\ast$& $\ast$ & $\ast$ & $\ast$ & $\ast$ &$\ast$  & $\ast$ & $\ast$ & $\ast$ & $\ast$ &$\ast$  &-- & \cellcolor{lightgray} & \\
%\color{green} prove\color{black}  &  $\ast$ & $\ast$ & $\ast$&  $\ast$&  $\ast$& $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ &$\ast$  & -- &-- & $\ast$ &$\ast$  & -- &-- & \cellcolor{lightgray} \\
%\color{orange} reveal\color{black}  &  $\ast$ & $\ast$ & $\ast$&  $\ast$&  $\ast$& $\ast$ & $\ast$ &$\ast$  &$\ast$  &$\ast$  &$\ast$  & $\ast$ &$\ast$  &$\ast$  & $\ast$ & -- & -- & -- & \cellcolor{lightgray}\\
%\color{green} announce\color{black}  & $\ast$  & $\ast$ & $\ast$&  $\ast$&  $\ast$&$\ast$  &$\ast$  &$\ast$  &$\ast$  &$\ast$  &$\ast$  &$\ast$  &$\ast$  &$\ast$  &$\ast$  &$\ast$  & -- &$\ast$  &$\ast$  & \cellcolor{lightgray} \\
%\color{green} be right\color{black}  &  $\ast$ & $\ast$ & $\ast$&  $\ast$&  $\ast$& $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & -- & $\ast$ & -- & -- & \cellcolor{lightgray}\\
%\color{green} establish\color{black}  &  $\ast$ & $\ast$ & $\ast$& $\ast$&  $\ast$& $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & -- & -- & \cellcolor{lightgray} \\
%\color{green} confirm\color{black}  &  $\ast$ & $\ast$ & $\ast$&  $\ast$&  $\ast$&$\ast$  &$\ast$  &$\ast$  &$\ast$  &$\ast$  &$\ast$  &$\ast$  &$\ast$  &$\ast$  &$\ast$  & $\ast$ &$\ast$  & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & \cellcolor{lightgray}\\
%\color{green} suggest\color{black}  &  $\ast$ & $\ast$ & $\ast$&  $\ast$&  $\ast$& $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ &$\ast$  &$\ast$  &$\ast$  &-- & \cellcolor{lightgray}\\
%\color{green} think\color{black}   &  $\ast$  & $\ast$ & $\ast$&  $\ast$&  $\ast$& $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & -- & -- & \cellcolor{lightgray} \\
%\color{green} say\color{black}   &  $\ast$  & $\ast$ & $\ast$&  $\ast$&  $\ast$& $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & $\ast$ & -- & -- \\
%\bottomrule
%\end{tabular}
%\caption{Posterior distributions of estimated marginal means of pairwise differences in the explicit ignorance context, with expressions ordered by mean naturalness rating. `*' indicates a difference in means, that is, the posterior distribution does not include 0, `--' indicates no difference in means, that is, the posterior distribution includes 0.}\label{t:pairwise}
%\end{table}

\begin{table}[!h]
\addtolength{\tabcolsep}{-.19em}
\centering
\begin{tabular}{r | cccccccccccccccccccccccccc}
& \rots{continue} & \rots{too} & \rots{also} & \rots{again} & \rots{stop} & \rots{\color{orange}be annoyed\color{black}} & \rots{cleft} & \rots{\color{orange}know\color{black}} & \rots{\color{green}demonstrate\color{black}} & \rots{\color{green}pretend\color{black}} & \rots{\color{green}inform\color{black}} & \rots{\color{green}confess\color{black}} & \rots{\color{orange}see\color{black}} & \rots{\color{green}acknowledge\color{black}} & \rots{\color{orange}discover\color{black}} & \rots{\color{green}admit\color{black}} & \rots{\color{green}hear\color{black}} & \rots{\color{green}prove\color{black}} & \rots{\color{orange}reveal\color{black}} & \rots{\color{green}announce\color{black}} & \rots{\color{green}be right\color{black}} & \rots{\color{green}establish\color{black}} & \rots{\color{green}confirm\color{black}} & \rots{\color{green}suggest\color{black}} & \rots{\color{green}think\color{black}} & \rots{\color{green}say\color{black}} \\
\hline
\input{../../results/main/13explicitIgnorance/models/latex-tables/table1}
\hline
\end{tabular}
\caption{Posterior distributions of estimated marginal means of pairwise differences in the explicit ignorance context, with expressions ordered by mean naturalness rating in the same context. Color coding indicates whether the difference was positive or negative, and the size of the difference; a white cell means that there was no difference: \\
Positive difference: \colorbox{yellow1}{\makebox[4em][c]{$>=-1.5$}}, \colorbox{yellow2}{\makebox[4em][c]{($-1.5, -0.5]$}}, \colorbox{yellow3}{\makebox[4em][c]{($-0.5, 0]$}} \\
Negative difference: \colorbox{purple1}{\makebox[4em][c]{$>=1.5$}}, \colorbox{purple2}{\makebox[4em][c]{($1.5,0.5]$}}, 
\colorbox{purple3}{\makebox[4em][c]{($0.5, 0]$}} 
}\label{t:pairwise}
\end{table}

Contrary to what is assumed in \citealt{mandelkern-etal2020} and \citealt{kalomoiros-schwarz2021,kalomoiros-schwarz-JoS}, presuppositions are not invariably unnatural in explicit ignorance contexts. Rather, in line with what was assumed in \citealt{simons01} and \citealt{abusch10}, some presuppositions seem to be rated as more unnatural in such contexts than others. On the assumption that naturalness ratings in explicit ignorance contexts differentiate between undefeasible/hard presuppositions and defeasible/soft presuppositions, one might take the results of our experiment to suggest that the pre-state contents of {\em continue} and {\em again}, and the existence requirements of {\em too} and {\em also} are not defeasible. The CCs of {\em see, discover}, and {\em reveal}, on the other hand, might be taken to be defeasible. Contrary to what \citealt{abusch10} assumed, the existence requirement of the {\em it-}cleft is not as clearly undefeasible as that of other projective contents (\citealt{smith-hall11} also observed that the {\em it-}cleft did not pattern like a hard trigger in their experiment). Finally, the results of our experiment align with our observation about possible by-content variation in \citepos{mandelkern-etal2020} Exp.~3. Recall from above that in their Exp.~3, the pre-state of {\em continue} was judged as (numerically) less natural in explicit ignorance contexts than the CC of the cognitive predicate {\em be aware}. This result is in line with the result of our experiment that the pre-state of {\em continue} is judged as less natural than the CC of the cognitive predicate {\em know}.

In our experiment, the CC of {\em be annoyed} received lower naturalness ratings than the CC of {\em know}. This result leads to the undesirable conclusion that the CC of {\em be annoyed} is more plausibly analyzed as a presupposition (perhaps even a hard one) than the CC of {\em know}, regardless of whether naturalness ratings in explicit ignorance contexts are taken to distinguish hard and soft presuppositions (\citealt{simons01,abusch10}) or presuppositions and nonpresuppositions (\citealt{mandelkern-etal2020,kalomoiros-schwarz2021,kalomoiros-schwarz-JoS}). This conclusion is undesirable because the presupposition of emotive predicates like {\em be annoyed} is that the attitude holder believes the CC to be true (e.g., \citealt{heim92,karttunen2016}), not that the speaker believes the CC to be true, as with {\em know}. In (\ref{emo}), for instance, the speaker does not believe that Sally did not leave a tip. \citealt{karttunen2016} suggested that the inference to speaker belief is a generalized conversational implicature that comes about in contexts that support the ``default assumption'' that the beliefs of the speaker and the attitude holder are aligned (p.712).

\begin{exe}
\ex\label{emo} Sally misremembered not having left a tip and regretted it. \hfill (\citealt[712]{karttunen2016})
\end{exe}
Given this status of the CC of {\em be annoyed}, it is surprising that this content received lower mean naturalness ratings than any of the other purportedly factive predicates. After all, in a context in which the speaker is explicitly ignorant of the CC, the default assumption that the speaker's and the attitude holder's beliefs are aligned does not arise, and so the interrogative with {\em be annoyed} should be judged natural in the explicit ignorance context, as it only presupposes that the attitude holder, not the speaker, believes the CC.

One hypothesis for why the CC of {\em be annoyed} received such low ratings is that naturalness ratings in explicit ignorance context are sensitive to at-issueness. On this hypothesis, the explicit ignorance statement (e.g., {\em I don't know whether Julian dances salsa}) does not merely convey the speaker's ignorance about the content to be investigated, but also identifies that the speaker takes the question under discussion (QUD) to be whether the CC is true (?CC; e.g., {\em Does Julian dances salsa?}). The speaker's immediately following interrogative utterance is interpreted with respect to the QUD ?CC is true. If so, the naturalness of the interrogative is modulated by whether the QUD ?CC  together with the interpretation of the interrogative is a felicitous strategy of inquiry (\citealt[32f.]{roberts12}), that is, if the interrogative can be interpreted as inquiring about the CC. As shown in \citealt{tbd-variability}, projective content differs in whether it can be at-issue. The CCs of emotive predicates, including {\em be annoyed}, are particularly resistant to being interpreted as at-issue. Thus, an interrogative with {\em be annoyed} (e.g., {\em Is Cole annoyed that Julian dances salsa?}) is unlikely to be interpreted as congruent with the QUD ?CC (e.g., {\em Does Julian dance salsa?}). This incongruence may be why the CC of {\em be annoyed} received comparatively low naturalness ratings in an explicit ignorance context.

For the CC of {\em know}, Fig.~\ref{fig:acc-by-expression} shows a bimodal pattern for the naturalness ratings, with about half of the participants rating it as fairly unnatural in the explicit ignorance context and about half as fairly natural. For the first group of participants, one could assume either that they reacted to the contradiction between the speaker's explicit ignorance statement and the inference arising from the interrogative that the speaker believes the CC to be true, or one could assume an analysis along the same lines as for {\em be annoyed} above. For the second group of participants, those who judged speakers' utterances like (\ref{pros}) as fairly natural, one hypothesis is that they read both utterances with the rise-fall-rise melodies indicated by the ToBI transcription of the example,\footnote{Explain transcription, what is TOBI} that is, with rising pitch on each of the bold-faced expressions:

\begin{exe}
\ex\label{pros} \gll {\bf I} don't {\bf know} whether Julian dances {\bf salsa}. Does {\bf Cole} know that Julian dances {\bf salsa}? 
\\ L*+H {} {L* H-} {} {} {} {L* H-H\%} {} L*+H {} {} {} {} {\hspace*{.2cm} L-H\%} \\ \glt 
\end{exe}
Analyses of the rise-fall-rise contour generally agree that it conveys that the speaker is uncertain about something and that their utterance does not fully answer the QUD (though the analyses differ in other regards; see, e.g., \citealt{ward-hirschberg85,buering97,buering03,wagner-etal2013}). In the context of the utterance of the declarative in (\ref{pros}), which conveys that the speaker takes the QUD to be whether Julian dances salsa, the rise-fall-rise contour that the interrogative utterance is realized with conveys that this utterance does not fully answer the QUD, which in turn requires that the speaker is uncertain about the CC. Under this interpretation, utterances like (\ref{pros}) may be rated as natural.

In sum, naturalness ratings in explicit ignorance contexts do not support \citepos{mandelkern-etal2020} hypothesis that projection is a categorical property of content, or for a categorical distinction between presuppositions and nonpresupposition. Instead, the results suggest that naturalness ratings in explicit ignorance contexts may be sensitive to whether the content is defeasible, to at-issueness, and to prosody.

\subsubsection{Comparison of naturalness ratings across contexts}\label{s:analysis2}

We next consider whether presuppositions and nonpresuppositions differ with respect to the ratings in contexts in which the speaker is explicitly ignorant of the content and in contexts that are compatible with the content. Recall that \citealt{mandelkern-etal2020} expected presuppositions to be sensitive to their context manipulation (explicit ignorance vs.\ support) but not nonpresuppositions. Fig.~\ref{fig:acc-by-context} shows mean naturalness ratings for the CCs of the 20 \fcolorbox{black}{orange}{factive} and \fcolorbox{black}{green}{nonfactive} predicates in the three contexts featured in our experiment, with the predicates ordered by their mean naturalness ratings in the explicit ignorance context, as in Fig.~\ref{fig:acc-by-expression}. 

As shown, the effect of context is not uniform for the factive predicates. For {\em be annoyed} and {\em know} the mean naturalness rating is quite a bit lower in the explicit ignorance context than in the higher prior probability context, whereas the difference is much less pronounced for {\em see} and {\em discover}, and not observed for {\em reveal}. This latter pattern is also observed for several nonfactive predicates, including {\em confess, hear, announce}, and {\em be right}. Thus, naturalness ratings in explicit ignorance vs.\ higher prior probability contexts do not provide support for a categorical distinction between the CCs of factive and nonfactive predicates. A comparison between the explicit ignorance and lower prior probability contexts also suggests variation between the factive predicates: Whereas for {\em be annoyed} the mean naturalness ratings are lower in the explicit ignorance context than in the lower prior probability context, they are equally high for {\em know}, but lower in the lower prior probability context than the explicit ignorance context for {\em see, discover}, and {\em reveal}. This latter pattern is observed for all of the nonfactive predicates. Thus, naturalness ratings in explicit ignorance vs.\ lower prior probability contexts also do not provide support for a categorical distinction between the CCs of factive and nonfactive predicates. 

Finally, we observe that the prior probability of content modulates its naturalness ratings with all predicates, except {\em demonstrate} and {\em pretend}): Content is judged as more natural in a context in which it has a higher prior probability than in a context in which it has a lower prior probability. This result is in line with the result of \citealt{degen-tonhauser-openmind} based on an inference rating task.

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{../../results/main/13explicitIgnorance/graphs/naturalness-by-context-and-predicate}
\caption{\small{Mean naturalness rating by context and predicate (\fcolorbox{black}{orange}{factive}, \fcolorbox{black}{green}{nonfactive}); predicates ordered as in Fig.~\ref{fig:acc-by-expression}. Error bars indicate 95\% bootstrapped CIs. Violin plots indicate kernel probability density of participants' ratings}.}\label{fig:acc-by-context}
\end{figure}

These observations were confirmed by posthoc pairwise comparisons of the naturalness ratings in the three context for each of the 20 predicates using the `emmeans' package (\citealt{emmeans}). The input to the pairwise comparisons were 20 Bayesian mixed-effects beta regression models with weakly informative priors that were fitted using the `brms' package (\citealt{buerkner2017}). The models predicted, for each predicate, the naturalness ratings from a fixed effect of context (with treatment coding and `explicit ignorance' as reference level) and included random by-item intercepts. The pairwise comparisons provided us with posterior distributions of estimated marginal means of pairwise differences between the three contexts for each predicate. We assume that the naturalness ratings in two contexts differ when the posterior distribution of their difference does not include 0. See Supplement \ref{a:analysis1} for the full model output.

 As shown in Table \ref{t:pairwise2},\footnote{The full model output is available here: \url{LINK TO TABLE IN REPO}.} the model confirms that the effect of context is not uniform for the five factive predicates: The difference between the naturalness ratings in the higher prior probability context and the explicit ignorance context is larger for {\em be annoyed} than for {\em know}, which in turn is larger than for {\em see} and {\em discover}. For {\em reveal} there is no difference, just like for many nonfactive predicates, such as {\em admit, hear, announce} and {\em be right}. The comparison of the lower prior probability context and the explicit ignorance context reveals a positive difference for {\em be annoyed}, no difference for {\em know} and a negative difference for {\em see, discover}, and {\em reveal}. Finally, there is a positive difference between the higher and lower prior probability context for all 20 predicates except for {\em demonstrate} and {\em pretend}.
 
\begin{table}[!h]
\addtolength{\tabcolsep}{-.19em}
\centering
\begin{tabular}{r  cccccccccccccccccccc}
& \rots{\color{orange}be annoyed\color{black}} & \rots{\color{orange}know\color{black}} & \rots{\color{green}demonstrate\color{black}} & \rots{\color{green}pretend\color{black}} & \rots{\color{green}inform\color{black}} & \rots{\color{green}confess\color{black}} & \rots{\color{orange}see\color{black}} & \rots{\color{green}acknowledge\color{black}} & \rots{\color{orange}discover\color{black}} & \rots{\color{green}admit\color{black}} & \rots{\color{green}hear\color{black}} & \rots{\color{green}prove\color{black}} & \rots{\color{orange}reveal\color{black}} & \rots{\color{green}announce\color{black}} & \rots{\color{green}be right\color{black}} & \rots{\color{green}establish\color{black}} & \rots{\color{green}confirm\color{black}} & \rots{\color{green}suggest\color{black}} & \rots{\color{green}think\color{black}} & \rots{\color{green}say\color{black}} \\
\hline
\input{../../results/main/13explicitIgnorance/models/latex-tables/table2}
\hline
\end{tabular}
\caption{Posterior distribution of estimated marginal means of pairwise differences between the three contexts for each expression, with expressions ordered by mean naturalness rating in explicit ignorance context. Color coding indicates whether the difference was positive or negative, and the size of the difference; a white cell means that there was no difference: \\
Positive difference: \colorbox{yellow1}{\makebox[4em][c]{$>=-1.5$}}, \colorbox{yellow2}{\makebox[4em][c]{($-1.5, -0.5]$}}, \colorbox{yellow3}{\makebox[4em][c]{($-0.5, 0]$}} \\
Negative difference: \colorbox{purple1}{\makebox[4em][c]{$>=1.5$}}, \colorbox{purple2}{\makebox[4em][c]{($1.5,0.5]$}}, 
\colorbox{purple3}{\makebox[4em][c]{($0.5, 0]$}} 
}\label{t:pairwise2}
\end{table}

In contrast to \citepos{mandelkern-etal2020} Exp.~3, our experiment did not collect naturalness ratings in a support context that entails the relevant content but in higher and lower prior probability contexts that are compatible with the CC. As mentioned above, contemporary presupposition analyses (e.g., \citealt{heim83,vds92}) assume that presuppositions are by default globally accommodated when they are not entailed by or satisfied in the context, and they can be locally accommodated (e.g., under the polar question operator) to avoid contradiction, uninformativity or problems with binding. Such analyses lead us to expect that presuppositions are rated as natural in higher and lower prior probability contexts, as these contexts do not contradict the CCs, make the CCs uninformative, or lead to problems with binding. Contrary to this expectation, the CCs of the five purportedly factive predicates received lower ratings in the lower prior probability context than in the higher prior probability context, where they received ratings that are roughly comparable to those of the factive predicates investigated in \citealt{mandelkern-etal2020}.\footnote{In the support context, the CCs of {\em be aware} and {\em be happy} received a mean naturalness rating of about 4.4 and 4.7 out of 7 in \citepos{mandelkern-etal2020} Exp.~3 (based on Fig.~8 in their Appendix). In our higher prior probability context, the mean naturalness ratings for the CCs of the five factive predicates ranged from .64 ({\em reveal}) to .78 ({\em know}) on a scale from 0 to 1.} This result suggests that naturalness ratings are sensitive to the prior probability of content, such that an interrogative with a clause-embedding predicate is judged as more natural in a context in which the CC has a higher prior probability than in a context in which it has a lower prior probability. For contemporary analyses of presuppositions, the result means that local accommodation must be sensitive to the prior probability of content, not just to whether the content is contradictory or uninformative in the context. 
  
\section{General discussion}\label{s3}

The experiment was designed to investigate \citepos{mandelkern-etal2020} claim that the measure used in their Exp.~3 provides support for a categorical distinction between presuppositions and nonpresuppositions. Neither the by-content comparison of naturalness ratings in explicit ignorance contexts  in \S\ref{s:analysis1} nor the by-context comparison in \S\ref{s:analysis2} provided empirical support for a categorical distinction between the CCs of factive and nonfactive predicates, or, more generally, between presuppositions and nonpresuppositions. Rather, the results of the experiment provided further support for the result of \citealt{degen-tonhauser-language} that factive predicates are not a natural class that is categorically different from nonfactive predicates. In this section, we discuss theoretical and methodological implications of these results.

\subsection{What are presuppositions?}

Contemporary literature still frequently treats presuppositions as if they were a homogenous class, by characterizing them as contents that typically project out of entailment-canceling environments or by analyzing them as conventionally-coded felicity requirements (e.g., \citealt{mandelkern-etal2020}). However, research on projective content has long recognized that the set of contents that have been called presuppositions is heterogeneous. One dimension of variation that was already mentioned in \S\ref{s1} is projection. Experimental investigations in different languages suggest that contents traditionally called presuppositions exhibit variation in the strength of the inference to the content (e.g., \citealt{xue-onea11} on German, \citealt{tonhauser-guarani-variability} on Paraguayan Guaran\'i, and \citealt{demarneffe-etal-sub23,tbd-variability,degen-tonhauser-language} on English). In English, for instance, the CC of {\em discover} is less projective than the CC of {\em know}. These results challenge the traditional characterization of presuppositions on the basis of projection.

A second dimension of variation is whether the content is associated with what \citealt{brst-lang11} referred to as a `strong contextual felicity' constraint. Some presumed presuppositions are not associated with such a constraint, which means that they are judged to be acceptable in a context that is neutral with respect to the content. This is the case for the CC of {\em know}, illustrated in (\ref{scf}a), which is informative in such a context. Other presumed presuppositions are associated with such a constraint, that is, they are judged to be unacceptable in a context that does not entail or satisfy the content. This is the case for the existence requirement of {\em too}, illustrated in (\ref{scf}b).

\begin{exe}
\ex\label{scf} \citealt[78, 80]{brst-lang11}
\begin{xlist}
\ex Context: A girl backs out of a driveway and hits Susi's car. A woman comes running out of the house, apologizes that her daughter hit Susi's car, and says: \\ She knows that she has to use her glasses to drive.

\ex Context: Malena is eating her lunch, a hamburger, on the bus going into town. A woman who she doesn't know sits down next to her and says:
\\ \infelic Our bus driver is eating empanadas, too.

\end{xlist}
\end{exe}
This variation suggests that analyses of presuppositions as conventionally-coded felicity requirements generalize an analysis that is empirically justified for contents associated with a strong contextual felicity constraint to contents that are not associated with such a constraint. 

A third dimension of variation is at-issue, that is, whether the content can address the question under discussion: As shown in \citealt{tbd-variability}, contents traditionally called presuppositions vary in this regard: For instance, the pre-state content of {\em stop} and the CC of {\em discover} are more at-issue than the CCs of {\em know} and {\em be annoyed}. And, finally, there is the dimension investigated in our experiment, which was referred to as defeasibility by \citealt{simons01} and \citealt{abusch10}. While the variation observed in our experiment does not line up perfectly with the variation assumed in these works, the results of our experiment suggest that contents traditionally called presuppositions exhibit variation in how natural they are in explicit ignorance contexts. For instance,  the pre-state content of {\em continue} was rated as less natural than the pre-state content of {\em stop}, which was rated as less natural than the existential content of the {\em it-}cleft, which was rated as less natural than the CC of {\em see}, which was rated as less natural than the CC of {\em reveal}. 

These dimensions of variation show that the set of contents traditionally referred to as presuppositions does not constitute a natural class. It is in response to such variation that researchers have developed analyses of subsets of these contents that do not rely on a conventional specification of felicity conditions or assume uniform projection (e.g., \citealt{abrusan2011,abrusan2013,abrusan2016,abusch02,abusch10,romoli2015}). Consequently, research on projective content can no longer take for granted a characterization of ``presuppositions''  based on projection or an analysis as conventionally-specified felicity conditions.

\subsection{Are there factive predicates?}

As discussed in \citealt{degen-tonhauser-language}, factive predicates are variably defined as predicates whose CC is presupposed (e.g., \citealt{kiparsky-kiparsky70}) or as predicates whose CC is presupposed and entailed (e.g., \citealt{gazdar79a,schlenker10,abrusan2011}). \citealt{degen-tonhauser-language} did not, however, find empirical support for a natural class of `factive' predicates that is categorically distinct from nonfactive ones. First, based on the results of two experiments designed to investigate the projection of the CCs of (non)factive predicates as well as the analyses of three existing projection datasets for 45, 78, and 517 (non)factive predicates, respectively,\footnote{These datasets were the CommitmentBank (\citealt{demarneffe-etal-sub23}), the VerbVeridicality dataset (\citealt{ross-pavlick2019}), and the MegaVeridicality dataset (\citealt{white-rawlins-nels2018}).} this work suggested that projection does not provide support for a natural class of factive predicates that is categorically distinct from nonfactive ones. Second, based on four experiments designed to investigate the entailment of the CCs of (non)factive predicates as well as analyses of entailment in two of the aforementioned datasets, this work suggested that considering entailment in addition to presuppositionality also does not provide support for a natural class of factive predicates that is categorically distinct from nonfactive ones. 

\citealt{degen-tonhauser-language} used a variety of inference rating measures to investigate the projection of the CCs of (non)factive predicates: In some measures, participants read constructed examples, in others naturally occurring ones; in some, examples were presented with a context, in others without a context; in some, the examples had diverse content, in others, they had minimal lexical content; across the measures, the clause-embedding predicates were embedded under different entailment-canceling operators, participants were asked to respond to different questions, and participants gave their response on different scales and sliders. Despite this variation, the results invariably suggested that factive predicates are not categorically distinct from nonfactive ones. 

The experiment presented in this paper presents support for the claim that there is no natural class of factive predicates based on a different measure, namely naturalness ratings in explicit ignorance contexts. The CCs of the five purportedly factive predicates exhibited variation in how natural they were judged to be when the speaker was explicitly ignorant of the CC, and there were no differences between the CCs of {\em see, discover} and {\em reveal} and several nonfactive predicates. Thus, neither data based on inference rating measures nor data based on naturalness ratings in explicit ignorance contexts provide support for a natural class of factive predicates. As discussed in \citealt{degen-tonhauser-language}, ``the search for a class of factive predicates might continue'' (p.586), but we believe that it is more fruitful to investigate the more fine-grained distinctions between clause-embedding predicates that can lead to a better understanding of their use in discourse. We offer some suggestions in \S\ref{s:disc3} based on the naturalness ratings we collected.


\subsection{Is projection a categorical or a gradient property of content?}

\citealt[497]{mandelkern-etal2020} urged us to ``think twice before embracing a notion of [\ldots] projection that is gradient based on results from inference tasks alone'', advocating instead for a view of projection that is categorical. In this section, we turn to the question of whether projection is a categorical or a gradient property of content. Before addressing the question, we first consider what it is (not) about.

What the question is not about is the projection of {\em utterance content}. What we mean by that is the strength of the projection inference that a particular interpreter draws from a particular utterance of a sentence in which a content is contributed in the scope of an entailment-canceling operator. The empirical evidence pointed to in \S\ref{s1} shows that different interpreters draw projection inferences of varying strength. For instance, as shown in Fig.~\ref{fig:dt1a-JULIAN}, the 266 participants of \citepos{degen-tonhauser-language} Exp.~1a drew projection inferences of varying strength for the CC that Julian dances salsa from utterances of the interrogative {\em Did Scott discover that Julian dances salsa?} It is uncontroversial that this utterance content variability is gradient, not categorical. It is gradient because the projection of utterance content is sensitive to several factors on which interpreters differ, including their prior beliefs about the speaker or about the utterance content, their perception and interpretation of the prosodic realization of the utterances, and their assumptions about the question under discussion addressed by the utterance (e.g., \citealt{djaerv-bacovcin2020,degen-tonhauser-openmind,mahler2020,mahler-thesis,tonhauser-salt26,tbd-variability,tonhauser-etal-sub23}).\footnote{Also: noise, inattentiveness, but replication of variation exclude this.} 

\begin{figure}[h!]
\centering
\includegraphics[width=.8\textwidth]{../../results/main/13explicitIgnorance/graphs/mean-certainty-by-predicateType-JULIAN}
\caption{Participants' certainty ratings (measuring projection) of the CC that Julian dances salsa for the 20 \color{orange}factive \color{black} and \color{green}nonfactive \color{black} predicates investigated in Exp.~1a of \citealt{degen-tonhauser-language} (adapted by collapsing the nonfactive predicates into a single category).}\label{fig:dt1a-JULIAN}
\end{figure}

What the question about whether projection is gradient or categorical is about is {\em content}, where a content is, for instance, the CC of {\em discover}, the CC of {\em inform}, or the pre-state content of {\em stop}. Asking whether projection is gradient or categorical at this level of abstraction (that is, abstracting away from variation attributable to interpreter variability) amounts to asking whether the observed by-content variability (for instance that the CC of {\em discover} is less projective than the CC of {\em inform}; see Fig.~\ref{fig:dt1a}) is derived from underlying representations that are categorical or underlying representations that are not categorical. Two aspects of the underlying representations we consider here are speaker belief and lexical entries. A speaker who wants to communicate a content might have a belief in the content that is categorical (that is, they either believe that is is true or they are uncertain) or one that is gradient (in which case they believe that the content is true to some degree).\footnote{\citealt[498f.]{tbd-variability} already considered that speaker belief could be gradient or categorical.} Likewise, the expressions associated with the content (like {\em discover} or {\em stop}) could have lexical entries that either license a projection inference or not (categorical) or their lexical entries could be such that whatever is specified may license a projection inference depending on other factors in the uttered sentence (gradient). This means that there are four hypotheses for any given content:

\begin{table}[h]
\centering
\begin{tabular}{c | c c}
Hypothesis & speaker & lexicon  \\ \hline\hline
1 & categorical & categorical  \\ 
2 & categorical & {\bf gradient}  \\ 
3 & {\bf gradient} & categorical \\ 
4 & {\bf gradient} & {\bf gradient}  \\ 
\hline
\end{tabular}
\caption{Hypotheses about speaker belief and lexical entries for any given content.}\label{t:hyp}
\end{table}

Some of this hypothesis space has already been advocated for in the literature. Analyses like \citealt{heim83,vds92} and \citealt{potts05} align with hypotheses 1 and 3, as they assume that some expression (triggers of presuppositions or conventional implicatures) are conventionally specified to trigger projection. While these analyses do not specify whether speaker belief is categorical or gradient, one could assume, on the former view (hypothesis 1), that a speaker who believes that a content is true chooses an expression that triggers projection, whereas a speaker who is uncertain about a content chooses an expression that does not trigger projection. On the latter view (hypothesis 3), a speaker believes content to be true to some degree and chooses an expression that either triggers projection or not, depending on what comes closest to their degree of belief. On either view, interpreters might draw projection inferences of different strengths due to uncertainty about (the degree of) the speaker's belief. 

Analyses like those of \citealt{abrusan2011,abrusan2016,abusch02,abusch10,romoli2015} and \citealt{brst-salt10,simons-etal2017} could be taken to align with hypotheses 2 and 4. On some of these analyses, some expressions specify alternatives as part of their lexical entries and this specification of alternatives can, depending on other factors, give lead to a projection inference (e.g., \citealt{abusch02,abusch10,romoli2015}). On other analyses, entailed content may project in particular utterances  (e.g., \citealt{abrusan2011,abrusan2016,brst-salt10,simons-etal2017}). Crucially, while these analyses differ in many ways, they all share the assumption that the lexical entries of expressions do not categorically trigger (or not trigger) projection. Rather, whether a projection inference is licensed depends on a combination of the lexical entries and other utterance factors. These analyses, too, don't specify whether speaker belief is categorical or gradient.

To evaluate which of the four hypotheses in Table \ref{t:hyp} is appropriate for any given content, we have to consider the observed by-content variability. An extreme position is to assume for every projective content that speaker belief is categorical and triggered by conventional specification. To capture the observed by-content variability, one would then have to assume that it arises during utterance interpretation and affects different expression/content pairs differently. That does not seem plausible. A more plausible position seems to us to be one on which each of the four hypotheses is correct but for different sets of expression/content pairs. For instance, hypothesis 1 might be appropriate  the existence requirement of pronouns and {\em too} (expression/content pairs associated with a strong contextual felicity requirement), hypothesis 2 for the pre-state of {\em stop}, and hypothesis 4 for the CC of {\em inform}. The observed by-content variability would then be attributable to a combination of factors, with expression/content pairs differing on the factors and their relative weights. 

There is, to date, no projection analysis that can predict the observed by-content variability (for discussions, see \citealt{tbd-variability,degen-tonhauser-language}). What seems clear, given the observed by-content variability, is that the question of whether projection is a gradient or a categorical property of content does not have a single answer for all projective content. What the source of the variability is must be decided in future research that carefully compares...

\subsection{Future avenues in the investigation and theoretical analysis of projective content}\label{s:disc3}

What are naturalness ratings sensitive to?


- strong contextual felicity constraint
- at-issueness
- prior probability of content

\begin{itemize}

\item Lots of interesting properties of projective content to investigate

\item What do the naturalness ratings tell us about the lexical meanings of these predicates?


\item This result suggests that interrogatives are particularly acceptable when the speaker is either ignorant about the CC or the CC has a higher prior probability: to inquire about the CC, or to inquire about the matrix clause. 

\item We also observe that the mean naturalness rating is lower in the lower prior probability context than in the higher prior probability context, for all of the predicates except for {\em pretend}. This suggests that the prior probability of the CC modulates the naturalness of the interrogative regardless of whether the embedding predicate is factive, where the observed context-sensitivity is unexpected under standard analyses (e.g., \citealt{heim83,vds92}) or nonfactive (where it is expected). This result mirrors that of \citealt{degen-tonhauser-openmind}, who found in an inference rating task the strength of projection inferences to the CCs of factive and nonfactive predicates is modulated by the prior probability of the CC. One could, of course, propose to make the global accommodation of presuppositions to not be default but to be sensitive to the prior probability of content. But the fact of the matter is that the context-sensitivity is observed not just for factive but also for nonfactive predicates, thereby motivating a common projection mechanism.

\end{itemize}

measure doesn't just track anaphoric presuppositions but possibly also mismatches in at-issueness

does the measure track at-issueness or projection?

\section{Conclusions}\label{s4}




% end document here for word count
%\end{document}

\bibliographystyle{../cslipubs-natbib}
%\bibliographystyle{/Users/tonhauser.1/Library/Latex/cslipubs-natbib}
\bibliography{/Users/tonhauser.1/Documents/bibliography}

\newpage

\section*{Supplemental materials}

\appendix

\setcounter{page}{1}
%\renewcommand{\thetable}{A\arabic{table}}

\setcounter{table}{0}
\renewcommand{\thetable}{A\arabic{table}}

\setcounter{figure}{0}
\renewcommand{\thefigure}{A\arabic{figure}}

\section{Experiment stimuli}\label{a:clauses}

The twenty predicates used in the experiment are the same as in \citealt{degen-tonhauser-openmind,degen-tonhauser-language}:

\begin{exe}
\ex\label{predicates}
\begin{xlist}
\ex Factive: be annoyed, discover, know, reveal, see
\ex Non-factive: acknowledge, admit, announce, be right, confess, confirm, establish, hear, inform, pretend, prove, say, suggest, think
\end{xlist}
\end{exe}

Eventive predicates, like {\em discover} and {\em hear}, were realized in the past tense and stative predicates, like {\em know} and {\em be annoyed}, were realized in the present tense. The direct object of {\em inform} was realized by the proper name {\em Sam}. Each clause-embedding predicate was paired with a unique subject proper name. The speaker of the target stimuli was realized by a randomly sampled unique proper name. 

The following list shows the 20 clauses that realized the complements of the predicates in the target and filler stimuli, together with their lower and higher probability facts, respectively, that realized the preceding declarative sentences in the filler stimuli.

\begin{enumerate}[leftmargin=4ex,itemsep=-2pt]
\item Mary is pregnant. Facts: Mary is a middle school student / Mary is taking a prenatal yoga class
\item Josie went on vacation to France. Facts:  Josie doesn't have a passport / Josie loves France 
\item Emma studied on Saturday morning. Facts: Emma is in first grade / Emma is in law school 
\item Olivia sleeps until noon. Facts: Olivia has two small children / Olivia works the third shift
\item Sophia got a tattoo. Facts: Sophia is a high end fashion model / Sophia is a hipster
\item Mia drank 2 cocktails last night. Facts: Mia is a nun / Mia is a college student
\item Isabella ate a steak on Sunday. Facts: Isabella is a vegetarian / Isabella is from Argentina
\item Emily bought a car yesterday. Facts: Emily never has any money / Emily has been saving for a year
\item Grace visited her sister. Facts: Grace hates her sister / Grace loves her sister
\item Zoe calculated the tip. Facts: Zoe is 5 years old / Zoe is a math major
\item Danny ate the last cupcake. Facts: Danny is a diabetic / Danny loves cake
\item Frank got a cat. Facts: Frank is allergic to cats / Frank has always wanted a pet
\item Jackson ran 10 miles. Facts: Jackson is obese / Jackson is training for a marathon
\item Jayden rented a car. Facts: Jayden doesn't have a driver's license / Jayden's car is in the shop
\item Tony had a drink last night. Facts: Tony has been sober for 20 years / Tony really likes to party with his friends
\item Josh learned to ride a bike yesterday. Facts: Josh is a 75-year old man / Josh is a 5-year old boy
\item Owen shoveled snow last winter. Facts: Owen lives in New Orleans / Owen lives in Chicago
\item Julian dances salsa. Facts: Julian is German / Julian is Cuban
\item Jon walks to work. Facts: Jon lives 10 miles away from work / Jon lives 2 blocks away from work
\item Charley speaks Spanish. Facts: Charley lives in Korea / Charley lives in Mexico
\end{enumerate}

\section{Control and practice stimuli}\label{a:fillerPractice}

The following list shows the four control stimuli where the interrogative was expected to receive high naturalness ratings in the context of the preceding declarative sentence. The values in parentheses indicate the mean naturalness rating for each of the four controls. As shown, the third control did not receive the expected high naturalness mean ratings (probably because participants were unwilling to accommodate that Hendrick has a car in a context in which Hendrick was looking to buy a car). This control was therefore not used to exclude participants' data. 

\begin{enumerate}[leftmargin=4ex,itemsep=-2pt]

\item I don't know if Samantha has a new hat. Does Samantha have a new hat? (.89)

\item  I don't know if this pizza has mushrooms on it. Does this pizza have mushrooms on it? (.87)

\item Hendrick was looking to buy a car. Was Hendrick's car expensive? (.5)

\item Mary visited her aunt yesterday. Is Mary's aunt sick? (.91)

\end{enumerate}

\noindent
The following list shows the four practice stimuli in the order in which they were presented to the participants. Participants were able to advance to the experiment only if they gave a naturalness rating higher than .6 for the first and third stimulus, and a naturalness rating lower than .4 for the second and fourth stimulus.

\begin{enumerate}[leftmargin=4ex,itemsep=-2pt]

\item I have no idea where Natalie is from. Is Natalie from the USA?

\item I don't have any sisters. Have you met my sister yet?

\item I am going on vacation to Ireland. Does Fritz realize that Joe is going with me?

\item I have no idea if Anna has any dogs. Is Samuel glad that Anna fed her dogs?

\end{enumerate}

\section{Model output: Pairwise comparison of expressions}\label{a:analysis1}

{\bf JT PROPOSES TO LEAVE OUT THIS AND THE NEXT FIGURE}

Fig.~\ref{fig:comparisons1} provides a graphical representation of the results of the pairwise comparisons between the ratings for each expression in the explicit ignorance context. The full model output in table form is available here: \url{LINK TO TABLE IN REPO}.

\begin{sidewaysfigure}[h!]
\centering
\includegraphics[width=\textwidth]{../../results/main/13explicitIgnorance/graphs/comparisons-in-EIC}
\caption{.}\label{fig:comparisons1}
\end{sidewaysfigure}

\section{Model output: Pairwise comparison of contexts}\label{a:analysis2}

Fig.~\ref{fig:comparisons2} provides a graphical representation of the results of the pairwise comparisons of the ratings in the three contexts for each of the 20 predicates. The full model output in table form is available here: \url{LINK TO TABLE IN REPO}.

\begin{figure}[h!]
\centering
\includegraphics[width=.8\textwidth]{../../results/main/13explicitIgnorance/graphs/context-comparisons}
\caption{.}\label{fig:comparisons2}
\end{figure}
 
\end{document}

