%!TEX TS-program = xelatex
%!TEX encoding = UTF-8 Unicode

%% document settings
\documentclass[10pt]{article}
\usepackage{euler}
\usepackage{xunicode,xltxtra}
\usepackage{fontspec}

\usepackage[a4paper, margin = 1 in, left = .5 in, right = .5 in]{geometry}

\usepackage{setspace}
\usepackage[dvipsnames]{xcolor}

% fonts
	\defaultfontfeatures{Mapping=tex-text, Ligatures=TeX}
	\setromanfont[Mapping=tex-text, Numbers={Proportional}]{Linux Biolinum}
	\setsansfont[Scale=MatchLowercase,Mapping=tex-text]{Optima}
	\setmonofont[Scale=MatchLowercase]{Andale Mono}

\usepackage{amsmath}
\usepackage{amssymb}
% \usepackage{mathtools}
\usepackage{linguex}
\usepackage{booktabs}

\usepackage[colorlinks=true,citecolor=MidnightBlue,urlcolor=MidnightBlue,linkcolor=MidnightBlue]{hyperref}

\title{Effects on projectivity ratings by Embedding Operator and Trigger --- \newline Data Analysis}
\author{Lisa Hofmann}
\date{\today}

\begin{document}
\setkeys{Gin}{width=1.0\textwidth}
<<setup, include=FALSE, echo=FALSE>>=
library(knitr)
# library(highr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = xfun::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

knitr::opts_chunk$set(echo=TRUE, prompt=TRUE, comment=NA, tidy.opts=list(width.cutoff=50), 
                      fig.path='figures/figures', fig.align = "center", out.width="\\linewidth")
options(tidy=TRUE, linewidth = 100)
@

\maketitle
\setcounter{tocdepth}{2}
\tableofcontents

\section{Introducing the dataset}
<<load-data, echo=FALSE, results='hide'>>=
# set working directory to directory of script
# this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
# setwd(this.dir)
setwd("/Users/lisahofmann/Dropbox/Mein Mac (MBP-von-Lisa)/Documents/Academic/Research Projects/projective content/experiments-github/materials-lisa/analysis/3_projection-across-operators")

# load data
data <- read.csv("../../../results/main/meta-analyses/projectivity/data/data_combined.csv", 
                    header=TRUE, sep=",")

@

<<data-overview>>=
str(data)
data$workerid <- as.factor(data$workerid)
length(levels(data$workerid))
@


\noindent The dataset consists of $57160$ observations from $2682$ participants (recruited on the online platforms Prolific and Amazon Mechanical Turk), across 12 experiments.

We are interested in how highly participants rate speaker commitment to the truth of an embedded complement clause, coded as \texttt{projective} on a real-numbered sliding scale between $0-1$.\\

\noindent The complement clause was embedded under an attitude verb, which in turn was embedded under an entailment-cancelling operator. Our fixed effects factors manipulate the following:

\begin{enumerate}
  \item The choice of attitude verb (coded as \texttt{verb})
  \item The entailment-cancelling operator (coded as \texttt{op})
\end{enumerate}

\noindent The levels for our fixed effects factors are the following:
<<fixed-efcts-lvls>>=
data$verb <- as.factor(data$verb)
levels(data$verb)
length(levels(data$verb))
data$op <- as.factor(data$op)
levels(data$op)
length(levels(data$op))
@

\noindent We are interested in the effect on \texttt{projective} of \texttt{verb} and \texttt{op}, as well as their interaction, corresponding to a $20 \times 4$ factorial design, yielding
<<ncond>>=
length(levels(data$verb))*length(levels(data$op))
@
conditions.\\

\noindent We have $20$ items, corresponding to the content of the complement clause.
<<nitems>>=
data$content <- as.factor(data$content)
levels(data$content)
length(levels(data$content))
@

\noindent We have roughly $36$ observations by item and condition. This is an approximate number, because the \texttt{op} manipulation is a between-studies manipulation, and the number of participants differs by experiment:
<<nobs>>=
# n observations
length(data[,1])

# observations by item
length(data[,1])/length(levels(data$content))
table(data$content)

# observations by verb
length(data[,1])/length(levels(data$verb))
table(data$verb)

# observations by operator
length(data[,1])/length(levels(data$op))
table(data$op)

# observations by item and condition
length(data[,1])/length(levels(data$content))/
  (length(levels(data$verb))*length(levels(data$op)))

@

\newpage
\section{Data Overview and Statistical Summaries}
\subsection{Distribution of projectivity ratings by operator:}
<<project-by-op-distr, echo = FALSE, message=FALSE>>=
require(ggplot2)
require(dplyr)
data %>% 
  ggplot(aes(x = projective, group = op)) +
  facet_grid(rows = vars(op)) +
  geom_histogram(binwidth = .01, fill = "lightblue") +
  xlab("") +
  ylab("") +
  labs(title = "")+
  theme_bw()
@

\begin{itemize}
  \item These definitely do not look normal
  \item Maybe a beta-regression would be useful?
  \item But even that would be relying on some simplifying assumptions, since we might be ignoring the little bump in the middle 
\end{itemize}

\newpage
\subsection{Distribution of projectivity ratings by verb:}
<<project-by-v-distr, echo = FALSE>>=
data %>% 
  ggplot(aes(x = projective, group = verb)) +
  facet_wrap(vars(verb)) +
  geom_histogram(binwidth = .01, fill = "lightblue") +
  # coord_flip() +
  xlab("") +
  ylab("") +
  labs(title = "")+
  theme_bw()
@

\begin{itemize}
  \item Some of these also show a higher mass around the middle of the scale
  \item but it looks the beta-distribution could be useful
\end{itemize}


\newpage
\subsection{Means and confidence intervals for projectivity rating by operator}
<<summary-op, echo = FALSE, message=FALSE, cache=TRUE, out.width=".6\\textwidth">>=
# load helper functions
source('../../../results/main/helpers.R')
require(forcats)

proj_means_op = data %>% group_by(op) %>%
  summarize(Mean = mean(projective), CILow = ci.low(projective),
            CIHigh = ci.high(projective)) %>%
  mutate(YMin = Mean - CILow, YMax = Mean + CIHigh,
         op = fct_reorder(as.factor(op),Mean)) %>% ungroup()

proj_means_op %>% mutate(op = fct_reorder(op, Mean,
                                          .fun = mean)) %>%
  ggplot(aes(x = op, y=Mean)) +
  # coord_cartesian(ylim = c(0,1)) +
  geom_point(size = 1, color = "lightblue") +
  geom_errorbar(aes(ymin=YMin,ymax=YMax), width=0.1, color = "lightblue") +
  geom_line(color = "lightblue") +
  labs(title = "Mean projectivity by operator")+
  theme_bw() +
  scale_color_brewer(palette = "PRGn")
@

\noindent The following generalizations emerge:
\begin{itemize}
  \item Conditionals have the highest projectivity ratings
  \item Projectivity ratings for questions are higher than those for modals and negation, but lower than those for conditionals
  \item Modals and negation have the lowest projectivity ratings
  \item The ratings for negation look a little higher than for modals, but error bars overlap
\end{itemize}

\noindent Although these differences appear to be significant, they are quite small.\\

\newpage
\subsection{Means and confidence intervals for projectivity rating by verb:}
This will be replaced by violin-plot.
% <<summary-v, echo = FALSE, message=FALSE, cache=TRUE, fig.width=14, fig.height=7>>=
% 
% proj_means_v = data %>% group_by(verb) %>%
%   summarize(Mean = mean(projective), CILow = ci.low(projective),
%             CIHigh = ci.high(projective)) %>%
%   mutate(YMin = Mean - CILow, YMax = Mean + CIHigh,
%          verb = fct_reorder(as.factor(verb),Mean)) %>% ungroup()
% 
% proj_means_v %>% mutate(verb = fct_reorder(verb, Mean,
%                                          .fun = mean)) %>%
%   ggplot(aes(x=verb, y=Mean)) +
%   coord_cartesian(ylim=c(0,1)) +
%   geom_point(color = "lightblue") +
%   geom_errorbar(aes(ymin=YMin,ymax=YMax), width=0.1, color = "lightblue") +
%   labs(title = "Mean projectivity by predicate")+
%   theme_bw()
% @
\begin{itemize}
  \item We see gradual differences in projectivity between verbs
\end{itemize}

\subsection{Means and confidence intervals for projectivity rating by verb and operator:}
<<summary-combined, echo = FALSE, message=FALSE, cache=TRUE, fig.width=14, fig.height=7>>=

proj_means = data %>% group_by(verb, op) %>%
  summarize(Mean = mean(projective), CILow = ci.low(projective),
            CIHigh = ci.high(projective)) %>%
  mutate(YMin = Mean - CILow, YMax = Mean + CIHigh,
         verb = fct_reorder(as.factor(verb),Mean)) %>% ungroup()

proj_means %>% mutate(verb = fct_reorder(verb, Mean,
                                         .fun = mean)) %>%
  mutate(op = fct_reorder(op, Mean, .fun = mean)) %>%
  ggplot(aes(x=verb, y=Mean, group = op, color = op)) +
  coord_cartesian(ylim=c(0,1)) +
  geom_point(aes(shape = op), size = 4) +
  scale_shape_manual(values = c("M", "N", "Q", "C")) +
  geom_errorbar(aes(ymin=YMin,ymax=YMax),width=0.1) +
  geom_line() +
  labs(title = "Mean projectivity for predicate by operator")+
  theme_bw() +
  scale_color_brewer(palette = "PRGn")

@

\begin{itemize}
  \item We see interactions between verb and operator

  \item Two verbs show highest projectivity under negation: the anti-veridical \emph{pretend}, and the non-veridical \emph{think}. These are verb with relatively low overall projectivity.

  \item More projective verbs (\emph{\lq announce\rq} and above) have $\texttt{C} > \texttt{M}$

  \item Highly projective verbs (\emph{\lq hear \rq} and above) have  $\texttt{N} > \texttt{M}$

  \item We do not see any group of verbs that could be characterized as \lq semi-factive\rq\ in the sense of Karttunen.
  \begin{itemize}
    \item Specifically, \emph{discover} does not follow the predicted pattern: It is not more projective under negation, but most projective in conditionals and questions.
    \item For Karttunnen's \lq factives\rq, no difference between operators is expected.
    \item Kajsa Dj√§rv about this distinction: cognitive predicates are semi-factive, and emotives are factive. The pattern suggested by karrtunen is also not found here
  \end{itemize}

  \item For more generalizations, let's look at the same information plotted differently: By-operator projectivity for each verb
\end{itemize}


<<verb-profiles, echo = FALSE, message=FALSE, cache=TRUE, fig.width=14, fig.height=11>>=
proj_means %>% mutate(op = fct_reorder(op, Mean,
                                          .fun = mean)) %>%
  mutate(verb = fct_reorder(verb, Mean,
                            .fun = mean)) %>%
  ggplot(aes(x = op, y=Mean, group = verb)) +
  coord_cartesian(ylim = c(0,1)) +
  facet_wrap(vars(verb)) +
  geom_point(size = 1, color = "lightblue") +
  geom_errorbar(aes(ymin=YMin,ymax=YMax), width=0.1, color = "lightblue") +
  geom_line(color = "lightblue") +
  labs(title = "Mean projectivity by operator, for each verb")+
  theme_bw()


@
Some more generalizations: We find different \lq profiles\rq for different verbs, of how embedding operators affect projectivity based on the verb. Groups of verbs show similar profiles:

\begin{itemize}
  \item \emph{pretend, think}: \textbf{anti-veridical profile}\\
    \texttt{N} $>$ \texttt{M, Q, C}, overall low projectivity

  \item \emph{acknowledge, hear, inform, see, discover, know, be annoyed}: \textbf{\lq factive\rq\ profile}\\
    \texttt{Q} $>$ \texttt{N, C} \textcolor{gray}{$>_?$} \texttt{M}, overall high projectivity (it may be possible to find further subgroups here)

  \item \emph{prove, confirm, establish, demonstrate, (announce), confess, admit, reveal}: \textbf{veridical profile}\\
    \texttt{M, C} $>$ \texttt{Q} $>$ \texttt{N}, overall med-lo to med-hi projectivity
  
  \item \emph{be right, suggest}: \textbf{reportative profile}\\
    \texttt{M, N, C} $>$ \texttt{Q}

\end{itemize}

Maybe these can have better names, not trying to suggest that verbs can neatly divided in factive v non-factive, but potentially this class / profile is what prompted intuitions in previous literature, and naming in this tradition could make sense, but can be changed depending on our rhetoric, of course.

% \section{Analysis}
% 
% We are interested in how the response (projectivity ratings) depends on the verb and embedding operator, and whether the above generalizations can be supported statistically.
% 
% 
% 
% <<>>=
% formula <- response ~ op * verb
% # formula <- response ~ op * verb + (1 | workerid) + (1 | item)
% # formula <- response ~ op * verb + (1 + op + verb | workerid) + (1 + op + verb | item)
% @
% 
% Trying a beta-regression. Our response variable has observations from a sliding scale between $(0,1)$. For beta regression, we rescale it to $[0,1]$, using method used in Degen \& Tonhauser (2022), from Smithson \& Verkuilen (2006).
% 
% <<>>=
% data$response = (data$projective*(nrow(data)-1) + .5)/nrow(data)
% @
% 
% 
% <<>>=
% # library(rstan)
% # options(mc.cores=parallel::detectCores())
% # rstan_options(auto_write=TRUE)
% # library(brms)
% # 
% # model1 <- brm(formula = bf(response ~ op * verb ,
% #                            phi ~ op * verb,
% #                            family = Beta()),
% #               family = Beta(),
% #               data = data,
% #               iter=10000, warmup=2000,chains=6)
% 
% 
% @
% 
% 


\end{document}


